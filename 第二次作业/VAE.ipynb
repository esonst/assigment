{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import imageio,os\n",
    "# from keras.datasets import fashion_mnist as mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "latent_dim = 20\n",
    "epochs = 50\n",
    "num_classes = 10\n",
    "img_dim = 28\n",
    "filters = 16\n",
    "intermediate_dim = 256\n",
    "\n",
    "\n",
    "# 加载MNIST数据集\n",
    "data=np.load(\"mnist.npz\")\n",
    "x_train, y_train_, x_test, y_test_ =data['x_train'],data['y_train'],data['x_test'],data['y_test']\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1, img_dim, img_dim, 1))\n",
    "x_test = x_test.reshape((-1, img_dim, img_dim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                62740     \n",
      "=================================================================\n",
      "Total params: 127,732\n",
      "Trainable params: 127,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 搭建模型\n",
    "x = Input(shape=(img_dim, img_dim, 1))\n",
    "h = x\n",
    "\n",
    "for i in range(2):\n",
    "    filters *= 2\n",
    "    h = Conv2D(filters=filters,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               padding='same')(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    h = Conv2D(filters=filters,\n",
    "               kernel_size=3,\n",
    "               strides=1,\n",
    "               padding='same')(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "\n",
    "h_shape = K.int_shape(h)[1:]\n",
    "\n",
    "h = Flatten()(h)\n",
    "z_mean = Dense(latent_dim)(h) # p(z|x)的均值\n",
    "z_log_var = Dense(latent_dim)(h) # p(z|x)的方差\n",
    "\n",
    "encoder = Model(x, z_mean) # 通常认为z_mean就是所需的隐变量编码\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3136)              65856     \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DT (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DT (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 167,713\n",
      "Trainable params: 167,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z = Input(shape=(latent_dim,))\n",
    "h = z\n",
    "h = Dense(np.prod(h_shape))(h)\n",
    "h = Reshape(h_shape)(h)\n",
    "\n",
    "for i in range(2):\n",
    "    h = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=3,\n",
    "                        strides=1,\n",
    "                        padding='same')(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    h = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=3,\n",
    "                        strides=2,\n",
    "                        padding='same')(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    filters //= 2\n",
    "\n",
    "x_recon = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=3,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same')(h)\n",
    "\n",
    "\n",
    "decoder = Model(z, x_recon) # 解码器\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 7,946\n",
      "Trainable params: 7,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = decoder\n",
    "\n",
    "z = Input(shape=(latent_dim,))\n",
    "y = Dense(intermediate_dim, activation='relu')(z)\n",
    "y = Dense(num_classes, activation='softmax')(y)\n",
    "\n",
    "classfier = Model(z, y) # 隐变量分类器\n",
    "classfier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 32)   9248        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     18496       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 64)     36928       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 64)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3136)         0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           62740       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           62740       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 20)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 28, 28, 1)    167713      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_1 (Gaussian)           (None, 10, 20)       200         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 10)           7946        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 366,331\n",
      "Trainable params: 366,331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 重参数技巧\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# 重参数层，相当于给输入加入噪声\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "x_recon = decoder(z)\n",
    "y = classfier(z)\n",
    "\n",
    "\n",
    "class Gaussian(Layer):\n",
    "    \"\"\"这是个简单的层，只为定义q(z|y)中的均值参数，每个类别配一个均值。\n",
    "    输出也只是把这些均值输出，为后面计算loss准备，本身没有任何运算。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        self.num_classes = num_classes\n",
    "        super(Gaussian, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        latent_dim = input_shape[-1]\n",
    "        self.mean = self.add_weight(name='mean',\n",
    "                                    shape=(self.num_classes, latent_dim),\n",
    "                                    initializer='zeros')\n",
    "    def call(self, inputs):\n",
    "        z = inputs # z.shape=(batch_size, latent_dim)\n",
    "        z = K.expand_dims(z, 1)\n",
    "        return z * 0 + K.expand_dims(self.mean, 0)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_classes, input_shape[-1])\n",
    "\n",
    "gaussian = Gaussian(num_classes)\n",
    "z_prior_mean = gaussian(z)\n",
    "\n",
    "\n",
    "# 建立模型\n",
    "vae = Model(x, [x_recon, z_prior_mean, y])\n",
    "\n",
    "# 下面一大通都是为了定义loss\n",
    "z_mean = K.expand_dims(z_mean, 1)\n",
    "z_log_var = K.expand_dims(z_log_var, 1)\n",
    "\n",
    "lamb = 5 # 这是重构误差的权重，它的相反数就是重构方差，越大意味着方差越小。\n",
    "\n",
    "#重构误差---减小重构差异\n",
    "xent_loss = 0.5 * K.mean((x - x_recon)**2, 0)\n",
    "\n",
    "#方差的误差----减少方差\n",
    "kl_loss = - 0.5 * (1 + z_log_var - K.square(z_mean - z_prior_mean) - K.exp(z_log_var))\n",
    "kl_loss = K.mean(K.batch_dot(K.expand_dims(y, 1), kl_loss), 0)\n",
    "\n",
    "##  谁能告诉我，这是什么鬼\n",
    "cat_loss = K.mean(y * K.log(y + K.epsilon()), 0)\n",
    "\n",
    "vae_loss = lamb * K.sum(xent_loss) + K.sum(kl_loss) + K.sum(cat_loss)\n",
    "\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 80.8487 - val_loss: 50.7908\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 49.3390 - val_loss: 47.2689\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 46.8333 - val_loss: 45.6716\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 45.5750 - val_loss: 44.6035\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 44.6806 - val_loss: 43.8974\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 43.9671 - val_loss: 43.3868\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 43.2316 - val_loss: 42.8236\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 42.5703 - val_loss: 42.3279\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 42.1643 - val_loss: 41.8829\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 41.7226 - val_loss: 41.6668\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 41.4523 - val_loss: 41.7418\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 41.1801 - val_loss: 40.8521\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 40.9012 - val_loss: 40.5178\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 40.7061 - val_loss: 40.5444\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 40.5579 - val_loss: 40.7817\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 40.3822 - val_loss: 39.9299\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 40.2431 - val_loss: 40.0071\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 40.0764 - val_loss: 40.0587\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.9446 - val_loss: 39.8282\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.8675 - val_loss: 40.0434\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 39.7239 - val_loss: 39.8636\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.6236 - val_loss: 39.4426\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.5125 - val_loss: 39.2374\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 39.4362 - val_loss: 39.4153\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 39.3575 - val_loss: 39.9180\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.2808 - val_loss: 39.5566\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.2222 - val_loss: 39.2376\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.1406 - val_loss: 39.3984\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 39.0672 - val_loss: 38.8865\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 39.0300 - val_loss: 39.1122\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.9381 - val_loss: 39.2610\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.8252 - val_loss: 38.8609\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.7792 - val_loss: 39.3459\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 38.7283 - val_loss: 39.1932\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.6652 - val_loss: 38.9427\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.6475 - val_loss: 38.7811\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.5971 - val_loss: 38.6330\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 38.5206 - val_loss: 38.8772\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.5143 - val_loss: 38.7764\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 38.3970 - val_loss: 38.5870\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 38.4114 - val_loss: 38.8581\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.3621 - val_loss: 38.5146\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.3104 - val_loss: 38.6051\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.2845 - val_loss: 38.6274\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.2775 - val_loss: 38.2996\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.2090 - val_loss: 38.5476\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.1363 - val_loss: 38.3620\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 38.1592 - val_loss: 38.4538\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.1003 - val_loss: 38.2997\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 38.0602 - val_loss: 38.5504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217dbeaf518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, \n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [4.814487371837991e-28, 254.90527868270874]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 254.62692081928253]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [2.1751531643703153e-31, 254.60822582244873]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 254.6535649895668]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 254.3291687965393]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [5.455803629737747e-34, 254.42285656929016]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [2.18743476149013e-31, 254.69949692487717]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [1.036665364954856e-33, 254.7523444890976]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 254.6749046444893]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0.0, 254.86883103847504]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.8236666666666667\n",
      "test acc: 0.8296\n"
     ]
    }
   ],
   "source": [
    "means = K.eval(gaussian.mean)\n",
    "x_train_encoded = encoder.predict(x_train)\n",
    "y_train_pred = classfier.predict(x_train_encoded).argmax(axis=1)\n",
    "x_test_encoded = encoder.predict(x_test)\n",
    "y_test_pred = classfier.predict(x_test_encoded).argmax(axis=1)\n",
    "\n",
    "\n",
    "def cluster_sample(path, category=0):\n",
    "    \"\"\"观察被模型聚为同一类的样本\n",
    "    \"\"\"\n",
    "    n = 8\n",
    "    figure = np.zeros((img_dim * n, img_dim * n))\n",
    "    idxs = np.where(y_train_pred == category)[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            digit = x_train[np.random.choice(idxs)]\n",
    "            digit = digit.reshape((img_dim, img_dim))\n",
    "            figure[i * img_dim: (i + 1) * img_dim,\n",
    "            j * img_dim: (j + 1) * img_dim] = digit\n",
    "    imageio.imwrite(path, figure * 255)\n",
    "\n",
    "\n",
    "def random_sample(path, category=0, std=1):\n",
    "    \"\"\"按照聚类结果进行条件随机生成\n",
    "    \"\"\"\n",
    "    n = 8\n",
    "    figure = np.zeros((img_dim * n, img_dim * n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            noise_shape = (1, latent_dim)\n",
    "            z_sample = np.array(np.random.randn(*noise_shape)) * std + means[category]\n",
    "            x_recon = generator.predict(z_sample)\n",
    "            digit = x_recon[0].reshape((img_dim, img_dim))\n",
    "            figure[i * img_dim: (i + 1) * img_dim,\n",
    "            j * img_dim: (j + 1) * img_dim] = digit\n",
    "    imageio.imwrite(path, figure * 255)\n",
    "\n",
    "\n",
    "if not os.path.exists('samples'):\n",
    "    os.mkdir('samples')\n",
    "\n",
    "for i in range(10):\n",
    "    cluster_sample(u'samples/聚类类别_%s.png' % i, i)\n",
    "    random_sample(u'samples/类别采样_%s.png' % i, i)\n",
    "\n",
    "\n",
    "right = 0.\n",
    "for i in range(10):\n",
    "    _ = np.bincount(y_train_[y_train_pred == i])\n",
    "    right += _.max()\n",
    "\n",
    "print ('train acc: %s' % (right / len(y_train_)))\n",
    "\n",
    "\n",
    "right = 0.\n",
    "for i in range(10):\n",
    "    _ = np.bincount(y_test_[y_test_pred == i])\n",
    "    right += _.max()\n",
    "\n",
    "print ('test acc: %s' % (right / len(y_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
